\documentclass{article}
\usepackage[utf8]{inputenc}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
%
\theoremstyle{definition}
\newtheorem{theorem}{Theorem}
\newtheorem{definition}{Definition}
\newtheorem*{remark}{Remark}
\newtheorem*{notation}{Notation}
\newtheorem{construction}{Construction}

\title{Statistical Analysis of Permutations}
\author{Jojo W. Whaley Aboaf, Martin T. Wells}
\date{February 2021}

\begin{document}
\maketitle
\tableofcontents

\begin{abstract}
We Construct a general methods to analyze permutations.
We present an empirical method for analyzing ordered in order to test for nationality bias in International Surf Competitions.
We show this method can be applied in other settings, particularly for random graphs.

To state what we are setting out to do in its full generality simply:

- We are interested in a (finite) set of things, $E = \{e_1, e_2, \dots, e_n \} $
	
		- the number of things we are interested in is $|E| = n$

- We observe some data, $D = (d_i)_i^N$
		- each data point provides some information about a subset $ \{ e_a \: e_b \: \dots e_c \} \subseteq E$.
		- The number of things we observe are $|\{ e_a \: e_b \: \dots e_c \} |$ = k
        - We can observe
        	- a full ordering, for example $ [e_c \:  e_a \dots e_b] $
			- or a partial ordering, for example $ [e_c \: \{e_a, \dots, e_b\}], $equivalently $  [e_c \: \{e_b, \dots, e_a\}] $
            - or no ordering at all.
            
- We wish to assign $\mathbb{P}(Data | Model)$
Model  is 

\end{abstract}


\section{Introduction}

\paragraph{Ordered data} Recommendation systems attempt to leverage information regarding one’s preferences to suggest new content (e.g. music, movies) or products (e.g. books). Ranked-choice voting is used for local, provincial/state, and national level elections across the globe. Many institutions, such as Cornell University, use ranked-choice for its elections. In sports, orderings frequently determine tournament structures and season schedules, and in games or general forms of competition, ordered data is a natural way to express outcomes.

\paragraph{Graphical Data} Some Stuff about graphs blah blah blah THIS IS EVERYWHERE and everyone loves graphs.

\section{Background: Surfing}
Surfing has a long history, starting in BLANK with BLANK and spreading throughout the BLANK. Its origins are aesthetic and subliminal.

With growing interest in the dynamic sport, organized surf competition emerged over the past 60 years. The International Surfing Federation was founded in the 1960s and held a single event, the World Surfing Championships, every two years. After the ISF struggled with the event’s format and sponsorships, Fred Hemmings and Randy Rarick founded the world governing body of professional surfing, called International Professional Surfers (IPS). From 1976 to 1982, the IPS administered a series of events, called the World Circuit. Starting in 1983, the Association of Surfing Professionals (ASP) took over the operations of the ISP and renamed the “World Circuit,” the “World Championship Tour” (WCT). In 2015 the ASP rebranded to the World Surf League (WSL) and renamed the “World Championship Tour,” the “Championship Tour” (CT).  

The WSL Championship Tour (CT) is a series of events in which surfers are allocated points based on their placement in each of the constituent events and the surfer with the most points at the end of the season is crowned the WSL CT champion. While event formats and point allocation mechanisms have changed, surfers that advance though more rounds of an event are allocated more points. In addition to Championship Tour (CT), the WSL operates multiple Qualifying Series (QS): QS10000, QS6000, QS3000, QS1500, and QS1000. The number associated with a certain qualifying series indicates the number of points awarded to the winner of one of its constituent events. The specific breakdown of points awarded for various placement at QS events can be found in Appendix B of the WSL Rule Book.

In this paper, we focus on the 2017, 2018, and 2019 seasons of the Men’s Championship Tour because it offers the fullest set of waves that list judge scores along with their nationality.

However, a wide range of non-performance based biases are documented and researched using various methods; for example, Price and Wolfers study own-race bias in NBA refereeing using [        ], [   ] and [  ] investigate nationality bias in synchronized swimming judging using [       ], and ordering bias of gymnastics judges. These are only a few examples in sports, but the social-cognitive underpinnings of biases are a key area of research in psychology and legal studies.

This study uses 21,615 waves surfed in 2017, 2018, and 2019 seasons to empirically analyze the role of judge nationalities in the Men's Championship Tour.

\section{Construction}
\subsection{Motivation}
Our goal is to determine if judges have a tendency to give higher scores to surfers from their home country when compared to judges with a different home country.

For any given ride, there is one surfer. The surfer has a nationality. Each judge on the panel has a nationality. So we can identify two subsets of the panel:

Matching Judges = {judge on Panel | judge nationality = surfer nationality }
Non-Matching Judges = {judge on Panel | judge nationality != surfer nationality}

A judge in Matching Judges is called a match. A judge in Non-Matching Judges is called a non-match. This may seem to be a fairly straightforward statistical problem where testing for differences in means or rank tests may be applied. (These come with some dissatifactions though: wave scores are certainly not determined by parametric distributions of judge countries (they are functions of wave quality and surfer performance), we can only carry out rank tests on an individual wave because that is the only level at which scores are I.I.D, going up to heat level ie. multiple waves gives lots of variability from wave to wave and iid assumptions would be ridiculous.)

(In a way) we can answer our question by labelling each judge on the panel for a wave using $M :=\{$Match, Non-Match$\}$, and analyzing the frequencies of arrangements of M: [Match, Non-Match], [Non-Match, Match].

However, in analyzing our data from the "Match or Non-match" standpoint we have made the overarching assumption that the  surfer's country is immaterial, which is particularly concerning because it is the single factor determining if a judge is a match or non-match. And in this viewpoint "surfer A is from Brazil and Judge 3 is from Brazil " vs. "surfer B is from Australia and Judge 2 is from Australia". Precisely, the assumption is that, nationality bias is uniform over all of the countries. 

To analyze the orders of judges by nationality, it suffices to analyze the orderings of the set $C := \{AUS, BRA, FRA, \dots, ZAF\}$, which is the set of all nationalities of judges who scored any wave from 2017 to 2019.

In 2019 WCT, event      , round     , heat   , wave    . The surfer is     . The panel is composed of 5 judges with nationalities {  ,  ,  ,  ,  }. For this wave the matching judges are { , }, and the non-matching judges are { , , }.

In order to carry out these analyses with rigor, we must construct some methods for permutations.

\subsection{Symmetric Group}
\begin{definition}[The Symmetric Group on a set, $X$,] is $S_X := Isomorphisms(X,X)$. When $|X|<\infty$, $S_X = \{ \tau :X\rightarrow X \mid Image(\tau) = X \}  = \{\tau:X\rightarrow X \mid \{\tau(x) \mid x \in X\} = X \} $
\end{definition}
\begin{definition} $S_d := S_{\{ 1 ,\dots, d\}}. $\end{definition}

\begin{definition}When G is a Group, and $\mathbb{F}$ is a Field, the \textbf{Group Algebra of G over \mathbb{F}}, denoted $\mathbb{F}[G]$, is the space of formal linear combinations of elements of G. Elements of $\mathbb{F}[G]$ are of the form: $c_1 g_1 + \dots + c_n g_n = \sum^n_{i=1} c_i g_i$, where $c_i \in \mathbb{F}, g_i \in G$. Note that $i\neq j \implies g_i \neq g_j$ because G is a set of elements, so no element occurs with multiplicity. For example, $c_1 g + c_2 g \not\in \mathbb{F}[G]$ whereas $(c_1 + c_2)g \in \mathbb{F}[G]. $\end{definition}

\begin{remark} $\mathbb{F}[S_d]$ is comprised on formal linear combinations of elements of $S_d$. This may be understood as two different ways:
There exists a function $ a:S_n \rightarrow \mathbb{F}$ and $A :=  \sum_{\tau \in S_d} a(\tau) \tau \quad \in \mathbb{F}[S_n]$.
So: \[ A = [ \pi_1 \dots  \pi_{d!} ]  \] \[ \begin{pmatrix}a_{\pi_1}  \\  \vdots  \\  a_{\pi_{d!} }\end{pmatrix}\] = \sum_{\tau \in S_d } a_\tau \tau \in \mathbb{F} [S_d] \],where $\tau \in S_d, a_\tau \in \mathbb{F}$.
\end{remark}

\begin{definition}[Addition in $\mathbb{F}[S_n]$] is defined by $A+B = (\sum_{\tau} a_\tau \tau) + (\sum_\tau b_\tau \tau) = \sum_\tau (a_\tau + b_\tau) \tau $ \end{definition}
\begin{definition}[Scalar Multiplication in $\mathbb{F}[S_d]$] is $c(A) = c(\sum_{\tau} a_\tau \tau)  = \sum_{\tau} ca_\tau \tau$\end{definition}
\begin{definition} Multiplication in $\mathbb{F}[S_d]$ is \textit{defined} by
$ A*B 
=(\sum_{\tau} a_\tau \tau)* (\sum_\pi b_\pi \pi)
=\sum_{\gamma \in S_d}(\sum_{  \tau,\pi | \tau\pi = \gamma  } a_\tau b_\pi) \gamma
= \sum_{\gamma \in S_d}(\sum_{  \tau \in S_d} a_\tau b_{\tau^{-1}\gamma} ) \gamma
$ \end{definition}

\begin{remark} We should not over complicate $*$.
The \textit{definition} of $*$ may look odd, but it exactly the same as our basic understanding of multiplication: \(
(\sum_{  \tau} a_\tau\tau) *(\sum_{\pi }   b_\pi \pi)
= \sum_{  \tau} (a_\tau\tau) *(\sum_{\pi }   b_\pi \pi)
= \sum_{  \tau} \sum_{\pi }  (a_\tau\tau) * (b_\pi \pi)
= \sum_{  \tau}\sum_{\pi } a_\tau b_\pi \tau \pi
=\sum_{\gamma \in S_d}(\sum_{  \tau,\pi | \tau\pi = \gamma  } a_\tau b_\pi) \gamma
=(\sum_{\tau} a_\tau \tau)* (\sum_\pi b_\pi \pi)
\). Even though $(\sum_{  \tau} a_\tau\tau) *(\sum_{\pi }   b_\pi \pi)$ is equal to the intuitive form, $\sum_{  \tau}\sum_{\pi } a_\tau b_\pi \tau \pi $, this is not an element of the the group algebra because elements are repeated in the sum, hence our chosen definition. Also, $*$ merely extends multiplication in the Field,$\cdot$, and the operation in the group, $\circ $, by $a_\tau \tau * b_\pi \pi = a_\tau \cdot b_\pi \tau \circ\pi = a_\tau b_\pi \tau \pi$, where the last equality is simply notation-reduction. 
\end{remark}

\begin{remark} Many authors call $*$ "convolution", however this terminology is superfluous. A*B(\psi) = A*B\psi $

\end{remark}

\subsection{Probability on The Symmetric Group}
\begin{definition} A measure on $S_d$, is an element of the group algebra $\mathbb{C}[S_n]$.\end{definition}
\begin{definition} A measure on $S_n$, $F = \sum_{\tau \in S_n} f_\tau \tau $, is a probability measure on $S_n$ if and only if $\forall \tau \in S_n f_\tau \geq 0 $ and $\sum_{\tau \in S_n} f_\tau = 1 $
\end{definition}

\begin{definition} A linear representation of a group G, is a group homomorphism, $\rho : (G,\circ) \rightarrow (GL(V),\cdot)$. A group homomorphism satisfies:
\item \(\forall x,y \in G \quad \rho(x\circ y) = \rho(x) \cdot \rho(y) \) where $\cdot $ is multiplication in $GL(V)$.
\item \( \rho(e) = I \), where e is the identity element in $G$ and I is the identity element in $ GL(V) $.
\item \( \forall x \in G, \rho(x^{-1}) = \rho(x)^*, \text{ where * denotes involution in GL(V)} \).
\end{definition}

\begin{definition}The representation of a measure F, is: $ \hat{F} := \sum_{\tau \in S_n} P(\tau) \rho(\tau) $. \end{definition}
Note: This is sometimes called the Fourier transform at a representation, I avoid that lingo. 

\begin{definition}(Convolution of two functions on $S_n$) is a binary operation $ A * B := \sum_{\tau \in S_n} a(\tau) b(\tau^{-1}g) $. equivalently:
\end{definition}

Note: $ \widehat{A*B} = \sum_{\gamma} (A*B)(\gamma)\rho(\gamma) 
= \sum_{\gamma } \sum_{\tau} a(\gamma \tau^{-1})b(\tau)\rho(\gamma )
= \sum_{\tau} \sum_{\gamma\tau } a(\gamma\tau \tau^{-1})b(\tau)\rho(\gamma\tau )
= \sum_{\tau} \sum_{\gamma\tau } a(\gamma )b(\tau)\rho(\gamma)\rho(\tau ) $
$ = \sum_{\tau} b(\tau)\rho(\tau ) \sum_{\gamma\tau } a(\gamma )\rho(\gamma) 
= \sum_{\tau} b(\tau)\rho(\tau ) \hat{A}
= \hat{A} \sum_{\tau} b(\tau)\rho(\tau )
= \hat{A} \cdot \hat{B} $

We take $\rho_n $ the permutation representation acting on the vector space $V := \mathbb{R}^n$ with basis indexed by $ \{1, \dots n\} $. So a typical element of V is of the form: 
\[ \begin{pmatrix} a^1 \\ a^2 \\ \vdots \\ a^n \end{pmatrix} = \begin{pmatrix} a^1 \\ 0 \\ \vdots \\ 0 \end{pmatrix} + \begin{pmatrix} 0 \\ a^2 \\ \vdots \\ 0 \end{pmatrix} + \dots + \begin{pmatrix} 0 \\  \vdots \\ 0\\ a^n \end{pmatrix} = a^1\begin{pmatrix} 1 \\ 0 \\ \vdots \\ 0 \end{pmatrix} + a^2\begin{pmatrix} 0 \\ 1 \\ \vdots \\ 0 \end{pmatrix} + \dots + a^n\begin{pmatrix} 0 \\  \vdots \\ 0\\ 1\end{pmatrix} = a^1 e_1 + a^2 e_2 + \dots a^n e_n \]which could be rewritten as $\sum_{i \in \{1,\dots,n\} } a^i e_i$. But remember, we are interested in functions that act on the basis.

For Example: $V_{M} := [ e_{\text{Match}} \: e_{\text{Non-Match}} ]$
For Example  : $V_{C} = [ e_{\text{AUS}} \: e_{\text{BRA}} \: \dots \: e_{\text{ZAF}} ]$


\subsection{Statistical Model for Permutations}

Idea #1:
Parameter Space (integer partitions of n): \(\Theta := \{ \theta \in \mathbb{N}^n \mid \sum_i \theta_i = n \} \)
Parametric Distribution (indicator on conjugate class): \( P_\theta(\tau) := \frac{ 1}{ |CL(\theta)| }1_{ \tau \in CL(\theta) } \)
Model: \( \mathcal{M}_\Theta := \{P_\theta \mid \theta \in \Theta \} \)

Idea #2
Parameter Space: \( \Theta := S_n\)
Parametric Distribution: \( P_\pi (\tau) := (\frac{1}{2})^{\{n}\)


Note: for any $A \in 2^{S_n} $, P(A) is not a number. P(A) is a set, namely the image of P when restricted to A. 

Given any probability measure, $P$, on $S_n$, the probability of $A$ w.r.t $P$ is $ P_A  := \sum_{\tau \in A} P(\tau) $, which may be represented as $\hat{P}_A := \sum_{\tau \in A} P(\tau) \rho(\tau) $, observe $\hat{P}_A = \sum_{\tau \in A} \hat{P}_\tau $. 

Point Mass at $\gamma$: $ P_\gamma(\tau) = 1 $ if $\tau = \gamma$ else 0
( MGF is $\exp(\hat{P}_\gamma)$ )

See other section.... I don't know why they are detached FIX!

Though this may seem a bit bland, consider how elements of a group may be constructed from a set of generators. Suppose $S_n$ is generated by the set K, ie. $S_n = < K > = <k_1, \dots, k_p >$. So we could construct a probability distribution defined by

\( P(\tau) = P( k_1^{a_1} \dots k_p^{a_p}) = P( k_1)^{a_1}\dots P(k_p )^{a_p} \) where $a_i$ are the smallest such $a_i$.

This provides an example of distributions that "factorize" into probabilities defined on a basis for the group (the basis criteria is necessary because if we can construct an element of $S_n$ in different ways with our generating set, then the value of $P(\tau)$ may not be well defined). (I HAVE TO MAKE THIS PRECISE, I HAVE NOTES ON THIS SOMEWHERE). It is not necessary that the generators generate the full symmetric group, only that the function is defined on every element.

An example of such a K is $K= \{(1,2), (1,3), \cdots, (1,n) \}$. Jojo... prove me this works. Implement it.

$S_n$ has some interesting structure.
The period of a permutation. (Sort of like a "Hitting time")
Really just a cyclic group generated by an element

\section{Probability Distributions}
\subsection{What is a Distribution on Permutations?}
Many models either implicitly or explicitly identify a distribution on a set of permutations. Paired Comparison Models do this by modelling pairs of objects and patching them all together. Thurstone Ordered Statistic models use normal random variables to assign probabilities to permutations ..... some more intro

What is a distribution on Permutations? Anything that can assign a number to an element of the symmetric group, ie. any function $f$ of the form \(f:\mathcal{S}_n \rightarrow \mathbf{R}_+ \). So what kind of things do we want from such a function? Here are the literature's axioms. 
% See Probability Models on Rankings by Critchlow, Flinger, Verducci

Re: label invariance & reversibility....
    don't these follow if you properly construct a model on the symmetric group?

Re: strong unimodality
    There are enough unimodal disrtibutions and models out there. Critchlow,Flinger,Verducci, dont give a reason this should be the case. I can construct useful, non-unimodal distributions.
    
complete concensus, and L-decomposability

\subsection{Methods of Constructing Distributions}

\section{Statistical Models}
\subsection{A Model for a Data Set}
Consider a set of data, \( \mathbf{X} := \{ x_i \}_{i=1}^N\)
Let \(
\Theta := \{ \theta \in \mathbf{R}_{\geq 0}^d \mid  \|\theta\|_1 = 1\} = \{x\in \mathbf{R}_{\geq 0}^d \mid \sum_{i=1}^d \theta_i = 1\} 
\) 
which defines the model, \(
\mathcal{M}_\Theta = \{ P_\theta \mid \theta \in \Theta \}
\)
What is $P_\theta$?

Well it could be a lot of things. We will present a couple of options and compare them. But first we make a key observation. 
We could have $ \forall \pi \in \mathcal{S}_n \: P_\theta(\pi) = P_\theta(\pi^{-1}) $
Or define some $c(\cdot):\mathcal{S}_n \rightarrow \mathbf{R} $ where $. c(\pi) = c(\pi^{-1}) $ so that $ \forall \pi \in \mathcal{S}_n \: P_\theta(\pi) + P_\theta(\pi^{-1})  = c( \pi ) $. More generally, $c(\cdot) $ would be considered a class function

Suppose \( P_\theta(\pi) := \frac{1}{n!}\sum_{i=1}^n \theta_i\theta_{\pi(i)} = \frac{1}{n!}\theta^t P_\pi\theta \) 
This would satisfy constant on conjugacy classes. ie. $ P_\theta(\pi) = P_\theta(\pi^{-1}) $

\subsection{A Model for a Data Sequence}
Suppose we are given a set of labels, L, and observe a sequence of N data points: $ (X_i \in S_L)_{i=1}^N$
It doesn't matter whether we wish to think of $X_i$ as a matrix or a element in the group... all the same.

(This is not a stochastic process. Measures in stochastic processes are invariant permutations. We are getting sequences of probability measures, none of which are invariant under $\pi \: \forall \pi \in S_L$. With the one exception being the uniform measure)

Suppose we are interested in how we move forward in our index (this could be interpreted as time). So we are interested in how we get from $X_i$ to $X_{i+1}$. Now suppose there exists a function F that tells us how we do in fact move forward in time.
Then F satisfies: $F X_i = X_{i+1} $. So we have $FX_i X_i^{-1} = X_{i+1}X_i^{-1} \implies FI = X_{i+1}X_i^{-1} \implies F = X_{i+1}X_i^{-1} $ 

Suppose we are interested in how we move backward in our index (such as moving back in time). So we want to know how to get from $X_{i+1}$ to $X_i$. Now suppose there is a function B that tells us how to move backward in time:
Then B satisfies: $BX_{i+1}= X_i$. So we have $BX_{i+1}X_{i+1}^{-1} = X_i X_{i+1}^{-1} \implies B I = X_i X_{i+1}^{-1} \implies  B = X_i X_{i+1}^{-1} $

Recall: $ F = X_{i+1}X_{i}^{-1}$ and $B = X_{i}X_{i+1}^{-1}$. Observe the relation: $F^{-1} = (X_{i+1}X_{i}^{-1})^{-1} = X_{i}X_{i+1}^{-1} = B$. Which gives $F = B^{-1}$.

Perhaps we are interested in the difference between backwards and forwards innovations, ie. the distribution, $F - B$. Which is the same as $F - F^{-1}$ and $B^{-1} - B$. The magnitude of the difference 


\subsection{Empirical Distributions}
We normally don't give this much thought, but it requires some here:
Each "data point" is an arrangement.



\section{Families of Distributions}
\subsection{General Exponential Models}
\subsection{Hyperbolic Functions}
Note: Using sinh and conh might lead to a more enlightening proof.f
Also, the remaining identities for hyperbolic functions follow from these)
$\sinh(\rho_\tau) := \frac{e^{\rho_\tau} - e^{-\rho_\tau}}{2} = \frac{e^{2\rho_\tau} - 1}{2e^\rho_\tau} = -\sinh(-\rho_\tau)$
$\cosh(\rho_\tau) := \frac{e^{\rho_\tau} + e^{-\rho_\tau}}{2} = \frac{1+e^{-2\rho_\tau}}{2e^{-\rho_\tau}}= \cosh(-\rho_\tau)$

Reminder: $e^{\rho_\tau}$ is an operator (which one may consider as a permutation with exponential density). If we let $A := e^{\rho_\tau} $ and $B:= e^{-\rho_\tau}$

\section{All of the defns}
\subsection{Symmetric Group}
\begin{definition}[Symmetric Group] The Symmetric Group is denoted $S_X$, and satisfies the following:
\begin{itemize}
\item \( \forall a,b \in \mathcal{S}_X  a \circ b \in \mathcal{S}_X \)
\item \( \exists e \in \mathcal{S}_X s.t. \forall a \in \mathcal{S}_X a \circ e = e \circ a = a\)
\item \( \forall a \in \mathcal{S}_X \exists b \in \mathcal{S}_X \: \text{s.t.} \: a \circ b = b \circ a = e\)
\end{itemize}
\end{definition}

\subsection{Graphs}
Some disclaimers:
The set of bi-directed graphs is a strict subset of the set of all graphs. 

ISSUE: V is a set, so no elements of V occur with multiplicity, which implies E has no multiplicities. This is not a problem until we construct graphs where multiple edges from v to u may occur, thought the larger the gragh we have the less probabale this is.

\end{document}
